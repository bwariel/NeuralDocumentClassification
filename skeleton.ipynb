{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skeleton.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "j5UeZiGlvNoH",
        "n52k6VoU1brz",
        "nkd4MHFQv0jS",
        "IRPpWCXA05ka",
        "ic-CaNISucO-",
        "XgN4fpA0uO8n",
        "_1Eq6TC2wicn",
        "OdGw-l6TEUiP",
        "nfLk6pw2M08a",
        "XXHM8y9kRW5V"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clemsage/NeuralDocumentClassification/blob/master/skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5UeZiGlvNoH",
        "colab_type": "text"
      },
      "source": [
        "# Settting up the computing environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n52k6VoU1brz",
        "colab_type": "text"
      },
      "source": [
        "## Install and import TensorFlow 2.0 with GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZVpUWUluZbV",
        "colab_type": "text"
      },
      "source": [
        "Select \"GPU\" in the Accelerator drop-down on Notebook Settings through the Edit menu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XYfp8LNcRD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0\n",
        "import tensorflow as tf\n",
        "print (tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkd4MHFQv0jS",
        "colab_type": "text"
      },
      "source": [
        "## Confirm TensorFlow can see the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbotnVwUpWBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRPpWCXA05ka",
        "colab_type": "text"
      },
      "source": [
        "## Additional information about hardware"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKpXrN-FzeKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8XAtu4u1mXZ",
        "colab_type": "text"
      },
      "source": [
        "For CPU information and RAM, run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mr3-8s-1jPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/cpuinfo\n",
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-CaNISucO-",
        "colab_type": "text"
      },
      "source": [
        "## Other useful package imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gevJulhruagf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import os\n",
        "import PIL\n",
        "import sys\n",
        "import importlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kDf1Kmntpwo",
        "colab_type": "text"
      },
      "source": [
        "# Working on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH2SxwR_1Rpu",
        "colab_type": "text"
      },
      "source": [
        "## Information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGLInZca1Pbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['form', 'email', 'handwritten', 'advertisement', 'invoice']\n",
        "num_classes = len(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgN4fpA0uO8n",
        "colab_type": "text"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQe3wu4U5kOt",
        "colab_type": "text"
      },
      "source": [
        "The dataset is a subset of the [RVL-CDIP dataset](https://www.cs.cmu.edu/~aharley/rvl-cdip/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVnJr5tzswrq",
        "colab_type": "text"
      },
      "source": [
        "First, clone or pull the GitHub repository of the project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST3fUpSmqncY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('NeuralDocumentClassification'):\n",
        "  !git clone https://github.com/clemsage/NeuralDocumentClassification.git\n",
        "else:\n",
        "  !git -C NeuralDocumentClassification pull\n",
        "sys.path.append('NeuralDocumentClassification')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zWbX_GYypxH",
        "colab_type": "text"
      },
      "source": [
        "Download and extract labels, images and dataset assignments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQJ8Kqy3sv_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import download_dataset\n",
        "importlib.reload(download_dataset)\n",
        "for elt in ['label', 'image', 'dataset_assignment']:\n",
        "  download_dataset.download_and_extract(elt)\n",
        "dataset_path = 'dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYoAg4lOau3h",
        "colab_type": "text"
      },
      "source": [
        "Parse `dataset_assignment.txt` to retrieve the training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4G-8jVJauWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = {\"training\": [], \"test\": []}\n",
        "with open(os.path.join(dataset_path, 'dataset_assignment.txt'), 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    line = line.split('\\n')[0]\n",
        "    file_id, assignment = line.split(',')\n",
        "    file_path = os.path.join(dataset_path, 'image_png', '%s.png' % file_id)\n",
        "    dataset[assignment].append(file_path)\n",
        "\n",
        "print(\"Number of training documents: %d\" % len(dataset[\"training\"]))\n",
        "print(\"Number of test documents: %d\" % len(dataset['test']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NRF5WhuiW3S",
        "colab_type": "text"
      },
      "source": [
        "List the image files of the training and test dataset (see [Load images tutorial](https://www.tensorflow.org/tutorials/load_data/images)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWG346GnPSKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_train_ds = tf.data.Dataset.from_tensor_slices(dataset['training'])\n",
        "list_train_ds = list_train_ds.shuffle(100000)\n",
        "list_test_ds = tf.data.Dataset.from_tensor_slices(dataset['test'])\n",
        "list_test_ds = list_test_ds.shuffle(100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93EnbGGRid77",
        "colab_type": "text"
      },
      "source": [
        "Print 5 image file names of the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlg7AAuoiAPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in list_train_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRu_CYsi06k",
        "colab_type": "text"
      },
      "source": [
        "Implement functions to convert a file path to an (image_data, label) pair:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U_FnyBjzwbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_class_indices = ['1', '2', '3', '4', '11']\n",
        "\n",
        "# Parse the labels.txt file to get all labels\n",
        "file_paths, labels = [], []\n",
        "with open(os.path.join(dataset_path, 'label.txt'), 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    line = line.split('\\n')[0]\n",
        "    file_id, label = line.split(',')\n",
        "    file_path = os.path.join(dataset_path, 'image_png', '%s.png' % file_id)\n",
        "    file_paths.append(file_path)\n",
        "    labels.append(raw_class_indices.index(label))\n",
        "\n",
        "labels_idx = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(keys=file_paths, \n",
        "                                                    values=labels),\n",
        "    default_value=tf.constant(-1))\n",
        "\n",
        "# Resize to the most frequent format in the dataset: Letter (8.5 by 11 inches)\n",
        "DPI = 35  # Number of Dots Per Inch\n",
        "IMG_WIDTH, IMG_HEIGHT = int(DPI * 8.5), int(DPI * 11)\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a uint8 tensor\n",
        "  img = tf.io.decode_png(img, channels=1)\n",
        "  # convert to floats in the [0,1] range\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size\n",
        "  img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
        "  return img\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = labels_idx.lookup(file_path)\n",
        "\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqyoYwtHH97_",
        "colab_type": "text"
      },
      "source": [
        "Apply image and label retrieval to the training and test datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5nmK9JFI-Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_train_ds = list_train_ds.map(process_path, \n",
        "                         num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "labeled_test_ds = list_test_ds.map(process_path, \n",
        "                         num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Eq6TC2wicn",
        "colab_type": "text"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWJshtOvIpfo",
        "colab_type": "text"
      },
      "source": [
        "Get image shape and label for one element of the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ7bN2jc0rNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, label in labeled_train_ds.take(1):\n",
        "  print(\"Image shape (height, width, depth):\", image.numpy().shape)\n",
        "  print(\"Label:\", class_names[label.numpy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVm4YLGH1Y9_",
        "colab_type": "text"
      },
      "source": [
        "Plot 5 random training images of each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET7vBNIU15pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(30, 60))\n",
        "n_images_per_class = 3\n",
        "images = {class_name: [] for class_name in class_names}\n",
        "\n",
        "for image, label in labeled_train_ds:\n",
        "  image = image.numpy()\n",
        "  label = label.numpy()\n",
        "\n",
        "  if len(images[class_names[label]]) < n_images_per_class:\n",
        "    images[class_names[label]].append(image)\n",
        "  \n",
        "  if all([len(images[class_name]) == n_images_per_class \n",
        "          for class_name in class_names]):\n",
        "    break\n",
        "\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "  for i in range(n_images_per_class):\n",
        "    plt.subplot(num_classes, n_images_per_class, \n",
        "                class_idx*n_images_per_class + i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.squeeze(images[class_name][i]), cmap='gray')\n",
        "    plt.xlabel(class_name)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTiy3OjTzPm7",
        "colab_type": "text"
      },
      "source": [
        "Get the class distribution in the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyrGh3szWs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt_class = Counter()\n",
        "for file_path in dataset['training']: \n",
        "  label = labels_idx.lookup(tf.constant(file_path))\n",
        "  cnt_class.update([class_names[label.numpy()]])\n",
        "\n",
        "for key, val in cnt_class.most_common():\n",
        "  print('%s: %d' % (key, val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vECBpU3JCxyt",
        "colab_type": "text"
      },
      "source": [
        "## Prepare training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxJ3RtsuK3nu",
        "colab_type": "text"
      },
      "source": [
        "Use a temporary folder for caching elements of the dataset in order to speed up training and testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx5JO952KSqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_train_ds = labeled_train_ds.cache('/tmp')\n",
        "labeled_test_ds = labeled_test_ds.cache('/tmp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSD1NL7g3kSt",
        "colab_type": "text"
      },
      "source": [
        "Shuffle the documents within each subset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYalPpQi3oeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_train_ds = labeled_train_ds.shuffle(2048)\n",
        "labeled_test_ds = labeled_test_ds.shuffle(2048)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOXl8eGcJP_J",
        "colab_type": "text"
      },
      "source": [
        "Batch documents within each subset:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejTxwX3KJ4Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "labeled_train_ds = labeled_train_ds.batch(batch_size)\n",
        "labeled_test_ds = labeled_test_ds.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-18lHiag4uiS",
        "colab_type": "text"
      },
      "source": [
        "Prefetch the subsets in the background while the model is training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je7kuYFh4y_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_train_ds = labeled_train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "labeled_test_ds = labeled_test_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQZqkwA5mRU",
        "colab_type": "text"
      },
      "source": [
        "# Visual classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcRvGBPJCPAI",
        "colab_type": "text"
      },
      "source": [
        "## Fully connected neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmD69yYP8Z7X",
        "colab_type": "text"
      },
      "source": [
        "### Set up the layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooKloCG47hA4",
        "colab_type": "text"
      },
      "source": [
        "Build a neural network composed of one fully connected (aka dense) layer with 128 hidden units and one output layer.\n",
        "\n",
        "Each image must be reshaped to a 1 dimensional vector before being fed to the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYxVCSLQ5tmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    #keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JjOGshU8ftf",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pHGhRxVD8wl-"
      },
      "source": [
        "Compile the model by providing the optimizer, the loss function you want to minimize and the metrics to monitor during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsnjxEZ8gJ1I",
        "colab_type": "text"
      },
      "source": [
        "Print the summary of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UUZ51MmgUhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GFuLNGh9U5w",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut4NKowCE8Hz",
        "colab_type": "text"
      },
      "source": [
        "Fit the model on the training preprocessed images for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nT6h3y_9XFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 15\n",
        "model.fit(labeled_train_ds, epochs=num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfLk6pw2M08a",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model performances on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIV9G61P3SB",
        "colab_type": "text"
      },
      "source": [
        "Get the values of the loss and accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq93ddH0NDpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(labeled_test_ds, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_gKCPtWVg3M",
        "colab_type": "text"
      },
      "source": [
        "Are these values different from their training counterparts ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXHM8y9kRW5V",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xHWavjURp-t",
        "colab_type": "text"
      },
      "source": [
        "Predict the class of for a random batch of the test set and retrieve their labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX0MIEONRkp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(iter(labeled_test_ds))\n",
        "\n",
        "# prediction\n",
        "predictions = model.predict(image_batch)\n",
        "predicted_classes_idx = np.argmax(predictions, axis=1)\n",
        "predicted_classes = [class_names[i] for i in predicted_classes_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyZFGQLLVFeC",
        "colab_type": "text"
      },
      "source": [
        "Plot 9 images of this batch, give their labels and predicted classes in the legend:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrgwVDo4VFG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(30, 40))\n",
        "\n",
        "for im_idx in range(9):\n",
        "  plt.subplot(3, 3, im_idx + 1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(np.squeeze(image_batch[im_idx]), cmap='gray')\n",
        "  plt.xlabel(\"label: %s\\npred: %s\" % (class_names[label_batch[im_idx]], \n",
        "                                      predicted_classes[im_idx]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monzP4ZVVkGr",
        "colab_type": "text"
      },
      "source": [
        "### Under the Hood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61YBF5sLfsrZ",
        "colab_type": "text"
      },
      "source": [
        "Implement the hidden (dense) layer by creating its weights and bias (see [documentation for custom layers](https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_layer_class)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HWRDQkPfBam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyHiddenLayer(keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyHiddenLayer, self).__init__()\n",
        "    w_init = tf.keras.initializers.GlorotUniform()\n",
        "    self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),\n",
        "                                              dtype='float32'),\n",
        "                         trainable=True)\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(initial_value=b_init(shape=(units,),\n",
        "                                              dtype='float32'),\n",
        "                         trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return keras.activations.relu(tf.matmul(inputs, self.w) + self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPOuiP_5ZGv",
        "colab_type": "text"
      },
      "source": [
        "Set up again the layers of the model using your custom hidden layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBd68qImh1zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unlike the default implementation, you need to give the input dimension of MyHiddenLayer\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "    MyHiddenLayer(128, IMG_HEIGHT*IMG_WIDTH),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z89v9Jcsj8S6",
        "colab_type": "text"
      },
      "source": [
        "Compile and retrain the resulting model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-0XL2RDkKFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(labeled_train_ds, epochs=num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnMkYilGngXs",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kaz6G-cbotNS"
      },
      "source": [
        "### Training from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ArNeT3D1nINR"
      },
      "source": [
        "### Leveraging pre-trained models (Transfer Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1WXZOzEvnINO"
      },
      "source": [
        "Get the final feature vectors generated by the Inception V3 model trained on ImageNet (browse models available on [TensorFlow Hub](https://tfhub.dev/)): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aDMImRlEnINF",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "inception_v3_url = \"https://tfhub.dev/google/tf2-preview/inception_v3/\" \\\n",
        "  \"feature_vector/4\"\n",
        "feature_extraction = keras.Sequential([hub.KerasLayer(inception_v3_url)])\n",
        "\n",
        "train_images_rgb = np.concatenate([train_images for _ in range(3)], axis=-1)\n",
        "feature_extraction(train_images_rgb).shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}