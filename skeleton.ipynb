{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skeleton.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "j5UeZiGlvNoH",
        "n52k6VoU1brz",
        "nkd4MHFQv0jS",
        "IRPpWCXA05ka",
        "ic-CaNISucO-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clemsage/NeuralDocumentClassification/blob/master/skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5UeZiGlvNoH",
        "colab_type": "text"
      },
      "source": [
        "# Settting up the computing environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n52k6VoU1brz",
        "colab_type": "text"
      },
      "source": [
        "## Install and import TensorFlow 2.0 with GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZVpUWUluZbV",
        "colab_type": "text"
      },
      "source": [
        "Select \"GPU\" in the Accelerator drop-down on Notebook Settings through the Edit menu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XYfp8LNcRD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0\n",
        "import tensorflow as tf\n",
        "print (tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkd4MHFQv0jS",
        "colab_type": "text"
      },
      "source": [
        "## Confirm TensorFlow can see the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbotnVwUpWBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRPpWCXA05ka",
        "colab_type": "text"
      },
      "source": [
        "## Additional information about hardware"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKpXrN-FzeKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8XAtu4u1mXZ",
        "colab_type": "text"
      },
      "source": [
        "For CPU information and RAM, run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mr3-8s-1jPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/cpuinfo\n",
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-CaNISucO-",
        "colab_type": "text"
      },
      "source": [
        "## Other useful package imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gevJulhruagf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kDf1Kmntpwo",
        "colab_type": "text"
      },
      "source": [
        "# Working on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH2SxwR_1Rpu",
        "colab_type": "text"
      },
      "source": [
        "## Information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGLInZca1Pbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['email', 'form', 'handwritten', 'invoice', 'advertisement']\n",
        "num_classes = len(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgN4fpA0uO8n",
        "colab_type": "text"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQe3wu4U5kOt",
        "colab_type": "text"
      },
      "source": [
        "Import the dataset - a subset of the [RVL-CDIP dataset](https://www.cs.cmu.edu/~aharley/rvl-cdip/) - from the Google Drive [PROVIDE_LINK]\n",
        "\n",
        "See [ways to import dataset in Google colab](https://medium.com/@master_yi/importing-datasets-in-google-colab-c816fc654f97)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFb00_d7uXl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples = {\"training\": 100, \"test\": 10}\n",
        "height_image, width_image = 800, 600\n",
        "\n",
        "images, labels = dict(), dict()\n",
        "for set_type, num_ex_set in num_examples.items():\n",
        "  images[set_type] = np.random.randint(low=0, high=256, \n",
        "                                       size=(num_ex_set, height_image, width_image, 1))\n",
        "  labels[set_type] = np.random.randint(low=0, high=num_classes, size=num_ex_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Eq6TC2wicn",
        "colab_type": "text"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEiZzLtsySCx",
        "colab_type": "text"
      },
      "source": [
        "Get the number of images in the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MvjZtzUyay_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(images[\"training\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcyi-6thyjpw",
        "colab_type": "text"
      },
      "source": [
        "Get the width, height and depth of each image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oz8SbEdy9a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(images[\"training\"][0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVm4YLGH1Y9_",
        "colab_type": "text"
      },
      "source": [
        "Plot 5 random training images of each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET7vBNIU15pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "n_images_per_class = 5\n",
        "\n",
        "for class_idx in range(num_classes):\n",
        "  labels_idx = np.where(labels[\"training\"] == class_idx)[0]\n",
        "  np.random.shuffle(labels_idx)\n",
        "  labels_idx = labels_idx[:n_images_per_class]\n",
        "  \n",
        "  for i in range(n_images_per_class):\n",
        "    plt.subplot(num_classes, n_images_per_class, \n",
        "                class_idx*n_images_per_class + i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.squeeze(images[\"training\"][labels_idx[i]]), cmap='gray')\n",
        "    plt.xlabel(class_names[labels[\"training\"][labels_idx[i]]])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTiy3OjTzPm7",
        "colab_type": "text"
      },
      "source": [
        "Get the class distribution in the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyrGh3szWs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print({class_names[key]: val for key, val in Counter(labels[\"training\"]).items()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdGw-l6TEUiP",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEgjIKeE0Wj",
        "colab_type": "text"
      },
      "source": [
        "Create a function called `preprocess_images` to reshape images to 299 x 299 pixels and scale the pixel values to the range [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAlJ5Z1KElLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_images(images, new_height_image=299, new_width_image=299):\n",
        "  images = tf.image.resize(images, (new_height_image, new_width_image))\n",
        "  images = images / 255.0\n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nVoN_EWWxSh",
        "colab_type": "text"
      },
      "source": [
        "Verify the resulting image shape and pixel values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgU0DSodWhBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = preprocess_images(images[\"training\"][0])\n",
        "\n",
        "print(im.shape)\n",
        "print(np.min(im))\n",
        "print(np.max(im))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQZqkwA5mRU",
        "colab_type": "text"
      },
      "source": [
        "# Visual classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcRvGBPJCPAI",
        "colab_type": "text"
      },
      "source": [
        "## Fully connected neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmD69yYP8Z7X",
        "colab_type": "text"
      },
      "source": [
        "### Set up the layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooKloCG47hA4",
        "colab_type": "text"
      },
      "source": [
        "Build a neural network composed of one fully connected (aka dense) layer with 128 hidden units and one output layer.\n",
        "\n",
        "Each image must be reshaped to a 1 dimensional vector before being fed to the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYxVCSLQ5tmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(new_height_image, new_width_image, 1)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JjOGshU8ftf",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pHGhRxVD8wl-"
      },
      "source": [
        "Compile the model by providing the optimizer, the loss function you want to minimize and the metrics to monitor during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GFuLNGh9U5w",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut4NKowCE8Hz",
        "colab_type": "text"
      },
      "source": [
        "Fit the model on the training preprocessed images for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nT6h3y_9XFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = preprocess_images(images[\"training\"])\n",
        "model.fit(train_images, labels[\"training\"], epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}